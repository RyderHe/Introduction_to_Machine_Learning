{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> Part 1 </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgm(t):\n",
    "    return 1 / (1 + np.exp(-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(n, d, sigma, w, b):\n",
    "    np.random.seed(0)\n",
    "    X = np.random.uniform(-1, 1, (n, d))\n",
    "    #np.random.seed(0)\n",
    "    u = np.random.rand(n,1)\n",
    "    y = []\n",
    "   \n",
    "    for i in range(n):\n",
    "        t = (np.dot(np.transpose(w), X[i]) + b) / sigma\n",
    "        if u[i][0] <= sgm(t):\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(-1)\n",
    "    y = np.array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6000\n",
    "d = 2\n",
    "sigma = 1\n",
    "b = 0\n",
    "# w\n",
    "temp1 = [1]\n",
    "temp2 = [0] * (d-1)\n",
    "w = temp1 + temp2\n",
    "w = np.array(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_gen(n, d, sigma, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09762701,  0.43037873],\n",
       "       [ 0.20552675,  0.08976637],\n",
       "       [-0.1526904 ,  0.29178823],\n",
       "       [-0.12482558,  0.783546  ],\n",
       "       [ 0.92732552, -0.23311696]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1,  1, -1,  1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> Part 2 </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  Bayes(X, y, w, b):\n",
    "    n = len(X)\n",
    "    correct = 0\n",
    "    for i in range(n):\n",
    "        # predict\n",
    "        y_hat = 0\n",
    "        if np.dot(np.transpose(w), X[i]) +b >= 0:\n",
    "            y_hat = 1\n",
    "        else:\n",
    "            y_hat = -1\n",
    "        # check correctness\n",
    "        if (y_hat == y[i]):\n",
    "            correct += 1\n",
    "    return (n - correct) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.361"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n = 6000\n",
    "Bayes(X, y, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bayes error of n = 6000 is 0.361."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> Part 3 </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the dataset into training samples and test samples\n",
    "\n",
    "split the generated dataset into n/2 training samples and n/2 test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 6000\n",
    "# each has 3000 smaples\n",
    "X_train = X[0: 3000] \n",
    "y_train = y[0: 3000]\n",
    "X_test = X[3000: 6000]\n",
    "y_test = y[3000: 6000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### knn classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{l1_Distance}$ return the Manhattan Distance between two samples $x_{1}$ and $x_{2}$ ie 1-norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_Distance(x1, x2):\n",
    "     return np.linalg.norm(x1 - x2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{l2_Distance}$ return the Euclidean Distance between two samples $x_{1}$ and $x_{2}$ ie 2-norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_Distance(x1, x2):\n",
    "     return np.linalg.norm(x1 - x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{findNearestNeighbors}$ collect the k most nearest points in training set for a given test point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findNearestPoints(trainX, testPointX, k, dist):\n",
    "    nearest_points = []\n",
    "    distances = []\n",
    "    n = len(trainX)\n",
    "    for i in range(n):\n",
    "        distance = 0\n",
    "        if (dist == \"l1\"):\n",
    "            distance = l1_Distance(trainX[i], testPointX)\n",
    "        else: \n",
    "            distance = l2_Distance(trainX[i], testPointX)\n",
    "        distances.append((trainX[i], distance, i))\n",
    "        \n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    \n",
    "    # first k points => smallest distance => nearest\n",
    "    for  i in range(k):\n",
    "        nearest_points.append([distances[i][0],distances[i][2]])\n",
    "        \n",
    "    return nearest_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{predictByNearestPoints}$ calculates the $\\hat{y_{i}}$ by taking the majority vote among each nearest points as predicted category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictByNearestPoints(nearest_points, trainY):\n",
    "    pos_votes = 0\n",
    "    neg_votes = 0\n",
    "    for i in range(len(nearest_points)):\n",
    "        idx = nearest_points[i][1]\n",
    "        if (trainY[idx] == 1):\n",
    "            pos_votes += 1\n",
    "        else :\n",
    "            neg_votes += 1\n",
    "    if pos_votes > neg_votes:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{predictionError}$ calculates the prediction errors by taking a ratio of total correct prediction out of all predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictionError(predictions, trueValues):\n",
    "    correct = 0\n",
    "    total = len(predictions)\n",
    "    for i in range(total):\n",
    "        if (predictions[i] == trueValues[i]):\n",
    "            correct += 1\n",
    "    #return round((correct/float(total) * 100.0, 3)\n",
    "    return (total - correct)/float(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: dist is either \"l1\" or \"l2\"\n",
    "\n",
    "\n",
    "$\\textbf{knn}$ simulates the k-NN classifier by using either $l_{1}$ distance or $l_{2}$ distance, and returns the predictions ($\\hat{testY}$) and the prediction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(trainX, trainY, testX, k, dist, testY):\n",
    "    size = len(testX)\n",
    "    predictions = [] # list of testYhat\n",
    "    for i in range(size):\n",
    "        #print(i)\n",
    "        nearest_points = findNearestPoints(trainX, testX[i], k, dist) #list of [point, idx]\n",
    "        predict = predictByNearestPoints(nearest_points, trainY)\n",
    "        predictions.append(predict)\n",
    "    errors = predictionError(predictions, testY)\n",
    "    return predictions, errors\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### knn classifier using $l_{2}$ distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = \"l2\"\n",
    "# k = 1\n",
    "testYhat_k1, errors_k1 = knn(X_train, y_train, X_test, 1, dist, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 3\n",
    "testYhat_k3, errors_k3 = knn(X_train, y_train, X_test, 3, dist, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 5\n",
    "testYhat_k5, errors_k5 = knn(X_train, y_train, X_test, 5, dist, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4513333333333333, 0.43333333333333335, 0.41133333333333333]\n"
     ]
    }
   ],
   "source": [
    "errors = [errors_k1, errors_k3, errors_k5]\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When k = 1, k-NN error is 0.4513333333333333.\n",
    "\n",
    "When k = 3, k-NN error is 0.43333333333333335.\n",
    "\n",
    "When k = 5, k-NN error is 0.41133333333333333."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> Part 4 </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### knn classifier using $l_{1}$ distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = \"l1\"\n",
    "# k = 1\n",
    "testYhat_k1, errors_k1 = knn(X_train, y_train, X_test, 1, dist, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 3\n",
    "testYhat_k3, errors_k3 = knn(X_train, y_train, X_test, 3, dist, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 5\n",
    "testYhat_k5, errors_k5 = knn(X_train, y_train, X_test, 5, dist, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4543333333333333, 0.43366666666666664, 0.41533333333333333]\n"
     ]
    }
   ],
   "source": [
    "errors = [errors_k1, errors_k3, errors_k5]\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When k = 1, k-NN error is 0.4543333333333333.\n",
    "\n",
    "When k = 3, k-NN error is 0.43366666666666664.\n",
    "\n",
    "When k = 5, k-NN error is 0.41533333333333333."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> Part 5 </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare Bayes error and 1-NN error for differnt $\\sigma$.\n",
    "\n",
    "For each $\\sigma$:\n",
    "\n",
    "1. generate dataset as part 1\n",
    "\n",
    "2. split training set and test set\n",
    "\n",
    "3. compute Bayes error (part 2) and 1-NN error(part 3) repectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bayes_vs_1nn(n, d, sigmas, w, b):\n",
    "    errors = []\n",
    "    for sigma in sigmas:\n",
    "        #generate dataset\n",
    "        X, y = data_gen(n, d, sigma, w, b)\n",
    "        # split the generated dataset into n/2 training samples and n/2 test samples\n",
    "        # n = 6000\n",
    "        X_train = X[0: 3000] \n",
    "        y_train = y[0: 3000]\n",
    "        X_test = X[3000: n]\n",
    "        y_test = y[3000: n]\n",
    "        # Bayes error\n",
    "        bayes_error = Bayes(X, y, w, b)\n",
    "        # 1-NN error\n",
    "        testYhat, error = knn(X_train, y_train, X_test, 1, \"l2\", y_test)\n",
    "        \n",
    "        print(\"sigma = \" + str(sigma) +\", bayes error = \" + str(bayes_error) + \",1-NN error = \" + str(error))\n",
    "        errors.append((bayes_error, error))\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 0.01, bayes error = 0.0065,1-NN error = 0.012333333333333333\n",
      "sigma = 0.1, bayes error = 0.066,1-NN error = 0.098\n",
      "sigma = 1, bayes error = 0.361,1-NN error = 0.4513333333333333\n",
      "sigma = 10, bayes error = 0.4726666666666667,1-NN error = 0.48\n"
     ]
    }
   ],
   "source": [
    "sigmas = [0.01, 0.1, 1, 10]\n",
    "# n = 6000\n",
    "errors = Bayes_vs_1nn(n, d, sigmas, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the report above:\n",
    "\n",
    "1. As $\\sigma$ increases, bayes error and 1-NN error both increase.\n",
    "\n",
    "2. For each $\\sigma$, bayes error is always lower than  1-NN error.\n",
    "\n",
    "3. For a large $\\sigma$, both the errors have an upper bounf of 50%. For a small $\\sigma$, 1-NN error is almost twice the Bayes error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
